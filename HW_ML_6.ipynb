{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#Load one of the built-in data sets and vectorise\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#wine = load_wine()\n",
    "#wine.head()\n",
    "print(wine.feature_names)\n",
    "print(wine.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATA FRAME \n",
    "wine_df=pd.DataFrame(np.c_[wine['data'],wine['target']],columns=np.append(wine['feature_names'],['target']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    float64\n",
      "sepal width (cm)     float64\n",
      "petal length (cm)    float64\n",
      "petal width (cm)     float64\n",
      "target               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the Categorical Variables\n",
    "df = pd.get_dummies(wine_df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2\n",
       "5                5.4               3.9                1.7               0.4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= wine_df.drop(['target'], axis=1)\n",
    "x.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "5    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=wine_df['target']\n",
    "y.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test datasets\n",
    "# 80:20 TRAIN AND TEST\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# we fit the train data\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# scaling the train and test data\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53315972  0.08921567 -1.28760767 -1.32191218]\n",
      " [-1.03958718 -1.81405202 -0.25752153 -0.25549563]\n",
      " [-1.28637345 -0.14869279 -1.34483468 -1.45521425]\n",
      " [ 0.81130987 -0.62450971  0.48642957  0.41101471]\n",
      " [-0.29922836 -1.3382351   0.08584051 -0.12219356]\n",
      " [-1.53315972  0.80294106 -1.34483468 -1.18861011]\n",
      " [ 0.19434419 -2.05196048  0.7153376   0.41101471]\n",
      " [ 0.31773733 -1.10032664  1.05869964  0.27771264]\n",
      " [ 0.44113046 -0.62450971  0.60088358  0.81092092]\n",
      " [ 0.81130987 -0.14869279  1.00147263  0.81092092]\n",
      " [-0.7928009   1.04084952 -1.28760767 -1.32191218]\n",
      " [-1.16298031 -0.14869279 -1.34483468 -1.32191218]\n",
      " [ 0.07095105  0.32712414  0.60088358  0.81092092]\n",
      " [-0.17583522 -1.10032664 -0.14306752 -0.25549563]\n",
      " [-0.05244208 -0.86241817  0.08584051  0.01110851]\n",
      " [-0.17583522 -0.38660125  0.25752153  0.14441057]\n",
      " [ 2.29202752  1.75457491  1.68819673  1.34412919]\n",
      " [ 0.19434419 -0.86241817  0.7725646   0.54431678]\n",
      " [-0.05244208 -0.62450971  0.7725646   1.61073333]\n",
      " [ 0.81130987 -0.14869279  0.82979161  1.07752505]\n",
      " [-1.28637345  0.80294106 -1.23038067 -1.32191218]\n",
      " [-0.42262149  1.04084952 -1.40206169 -1.32191218]\n",
      " [ 0.5645236   0.80294106  1.05869964  1.61073333]\n",
      " [ 0.68791674  0.32712414  0.42920256  0.41101471]\n",
      " [ 1.18148928 -0.14869279  1.00147263  1.21082712]\n",
      " [-1.03958718  0.5650326  -1.34483468 -1.32191218]\n",
      " [ 0.44113046  0.80294106  0.94424563  1.47743126]\n",
      " [ 0.31773733 -0.62450971  0.14306752  0.14441057]\n",
      " [-0.91619404  0.80294106 -1.28760767 -1.32191218]\n",
      " [-1.03958718  1.04084952 -1.23038067 -0.78870391]\n",
      " [ 1.05809615 -0.14869279  0.82979161  1.47743126]\n",
      " [-0.91619404  1.04084952 -1.34483468 -1.18861011]\n",
      " [ 0.81130987  0.32712414  0.7725646   1.07752505]\n",
      " [-0.17583522  1.75457491 -1.17315366 -1.18861011]\n",
      " [ 0.19434419 -0.14869279  0.60088358  0.81092092]\n",
      " [ 2.16863438 -0.14869279  1.63096972  1.21082712]\n",
      " [ 1.05809615  0.5650326   1.11592665  1.21082712]\n",
      " [ 0.5645236  -1.3382351   0.7153376   0.94422299]\n",
      " [ 1.18148928 -0.62450971  0.60088358  0.27771264]\n",
      " [-1.16298031 -1.3382351   0.42920256  0.67761885]\n",
      " [ 1.79845497 -0.38660125  1.4592887   0.81092092]\n",
      " [-0.29922836 -0.14869279  0.42920256  0.41101471]\n",
      " [-1.28637345 -0.14869279 -1.34483468 -1.18861011]\n",
      " [ 0.68791674 -0.62450971  1.05869964  1.21082712]\n",
      " [-1.16298031 -1.57614356 -0.25752153 -0.25549563]\n",
      " [ 1.67506183  0.32712414  1.28760767  0.81092092]\n",
      " [ 1.30488242  0.08921567  0.94424563  1.21082712]\n",
      " [-0.91619404  1.75457491 -1.05869964 -1.05530804]\n",
      " [-0.42262149 -1.57614356  0.0286135  -0.12219356]\n",
      " [ 0.44113046 -0.38660125  0.31474854  0.14441057]\n",
      " [ 0.31773733 -0.14869279  0.65811059  0.81092092]\n",
      " [-0.91619404 -1.3382351  -0.42920256 -0.12219356]\n",
      " [ 0.81130987 -0.14869279  1.17315366  1.34412919]\n",
      " [-0.05244208 -1.10032664  0.14306752  0.01110851]\n",
      " [-0.42262149 -1.10032664  0.37197555  0.01110851]\n",
      " [ 1.67506183 -0.14869279  1.17315366  0.54431678]\n",
      " [ 0.68791674  0.08921567  1.00147263  0.81092092]\n",
      " [-1.779946   -0.38660125 -1.34483468 -1.32191218]\n",
      " [-0.54601463  1.99248337 -1.17315366 -1.05530804]\n",
      " [ 0.31773733 -0.38660125  0.54365657  0.27771264]\n",
      " [-0.54601463  1.99248337 -1.40206169 -1.05530804]\n",
      " [ 1.42827556  0.32712414  0.54365657  0.27771264]\n",
      " [-0.91619404  0.5650326  -1.17315366 -0.92200597]\n",
      " [ 0.68791674 -0.62450971  1.05869964  1.34412919]\n",
      " [-0.7928009  -0.86241817  0.08584051  0.27771264]\n",
      " [-0.17583522 -0.62450971  0.20029453  0.14441057]\n",
      " [ 1.92184811 -0.62450971  1.34483468  0.94422299]\n",
      " [ 2.29202752 -0.62450971  1.68819673  1.07752505]\n",
      " [-0.54601463  0.80294106 -1.17315366 -1.32191218]\n",
      " [ 1.05809615  0.08921567  0.54365657  0.41101471]\n",
      " [-0.42262149 -1.57614356 -0.0286135  -0.25549563]\n",
      " [ 0.68791674 -0.86241817  0.88701862  0.94422299]\n",
      " [ 0.93470301 -0.14869279  0.37197555  0.27771264]\n",
      " [-1.16298031  0.08921567 -1.28760767 -1.45521425]\n",
      " [-1.03958718  0.80294106 -1.28760767 -1.32191218]\n",
      " [-0.17583522  3.18202568 -1.28760767 -1.05530804]\n",
      " [ 0.31773733 -0.62450971  0.54365657  0.01110851]\n",
      " [-1.16298031  0.08921567 -1.28760767 -1.32191218]\n",
      " [-0.05244208 -0.86241817  0.7725646   0.94422299]\n",
      " [ 1.18148928  0.32712414  1.23038067  1.47743126]\n",
      " [-0.29922836 -0.38660125 -0.08584051  0.14441057]\n",
      " [ 1.05809615  0.08921567  1.05869964  1.61073333]\n",
      " [ 1.05809615 -0.14869279  0.7153376   0.67761885]\n",
      " [-1.90333914 -0.14869279 -1.5165157  -1.45521425]\n",
      " [-0.7928009   2.46830029 -1.28760767 -1.45521425]\n",
      " [-0.29922836 -0.14869279  0.20029453  0.14441057]\n",
      " [-1.28637345  0.08921567 -1.23038067 -1.32191218]\n",
      " [-0.91619404  1.75457491 -1.28760767 -1.18861011]\n",
      " [-1.03958718 -0.14869279 -1.23038067 -1.32191218]\n",
      " [ 0.68791674 -0.38660125  0.31474854  0.14441057]\n",
      " [ 2.29202752 -0.14869279  1.34483468  1.47743126]\n",
      " [-0.05244208  2.23039183 -1.4592887  -1.32191218]\n",
      " [-0.7928009   0.80294106 -1.34483468 -1.32191218]\n",
      " [ 0.5645236  -1.3382351   0.65811059  0.41101471]\n",
      " [-0.17583522 -0.62450971  0.42920256  0.14441057]\n",
      " [-0.91619404  1.75457491 -1.23038067 -1.32191218]\n",
      " [ 0.5645236  -0.38660125  1.05869964  0.81092092]\n",
      " [-1.40976659  0.32712414 -1.40206169 -1.32191218]\n",
      " [-1.03958718  1.04084952 -1.40206169 -1.18861011]\n",
      " [-1.03958718 -2.52777741 -0.14306752 -0.25549563]\n",
      " [-1.28637345  0.80294106 -1.05869964 -1.32191218]\n",
      " [ 0.19434419 -0.38660125  0.42920256  0.41101471]\n",
      " [-0.66940777  1.51666645 -1.28760767 -1.32191218]\n",
      " [-0.54601463 -0.14869279  0.42920256  0.41101471]\n",
      " [ 1.30488242  0.08921567  0.7725646   1.47743126]\n",
      " [ 1.05809615  0.08921567  0.37197555  0.27771264]\n",
      " [ 0.19434419  0.80294106  0.42920256  0.54431678]\n",
      " [ 2.29202752 -1.10032664  1.80265074  1.47743126]\n",
      " [-0.29922836 -0.62450971  0.65811059  1.07752505]\n",
      " [-1.03958718  0.80294106 -1.23038067 -1.05530804]\n",
      " [-0.54601463  1.51666645 -1.28760767 -1.32191218]\n",
      " [ 1.30488242  0.32712414  1.11592665  1.47743126]\n",
      " [-0.05244208 -0.86241817  0.7725646   0.94422299]\n",
      " [ 0.07095105 -0.14869279  0.25752153  0.41101471]\n",
      " [ 0.5645236  -1.81405202  0.37197555  0.14441057]\n",
      " [-0.29922836 -0.86241817  0.25752153  0.14441057]\n",
      " [-1.16298031  1.27875798 -1.34483468 -1.45521425]\n",
      " [-0.91619404  1.04084952 -1.34483468 -1.32191218]\n",
      " [-1.53315972  1.27875798 -1.57374271 -1.32191218]\n",
      " [ 0.5645236  -0.62450971  0.7725646   0.41101471]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=8000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# creating an classifier from the model:\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=8000)\n",
    "\n",
    "# let's fit the training data to our model\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model1_train = mlp.predict(x_train)\n",
    "print(accuracy_score(model1_train, y_train))\n",
    "model1_test = mlp.predict(x_test)\n",
    "print(accuracy_score(model1_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.25, hidden_layer_sizes=(18, 18), random_state=1,\n",
      "              solver='lbfgs')\n"
     ]
    }
   ],
   "source": [
    "# Training with different hyperparameters\n",
    "mlp2 = MLPClassifier(solver='lbfgs', alpha=.25,\n",
    "                    hidden_layer_sizes=(18, 18), random_state=1)\n",
    "\n",
    "print(mlp2.fit(x_train, y_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833333333333333\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model2_train = mlp2.predict(x_train)\n",
    "print(accuracy_score(model2_train, y_train))\n",
    "model2_test = mlp2.predict(x_test)\n",
    "print(accuracy_score(model2_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.92954914\n",
      "Iteration 2, loss = 0.92783880\n",
      "Iteration 3, loss = 0.92541049\n",
      "Iteration 4, loss = 0.92234615\n",
      "Iteration 5, loss = 0.91872141\n",
      "Iteration 6, loss = 0.91460758\n",
      "Iteration 7, loss = 0.91007111\n",
      "Iteration 8, loss = 0.90517277\n",
      "Iteration 9, loss = 0.89996706\n",
      "Iteration 10, loss = 0.89450390\n",
      "Iteration 11, loss = 0.88882446\n",
      "Iteration 12, loss = 0.88297704\n",
      "Training loss did not improve more than tol=0.500000 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(alpha=0.25, hidden_layer_sizes=28, max_iter=2000, random_state=1,\n",
      "              solver='sgd', tol=0.5, verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Training model with different hyperparameters\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(28), max_iter=2000, alpha=.25,\n",
    "                    solver='sgd', verbose=10, tol=.5, random_state=1,\n",
    "                    learning_rate_init=.001)\n",
    "print(mlp3.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model3_train = mlp3.predict(x_train)\n",
    "print(accuracy_score(model3_train, y_train))\n",
    "model3_test = mlp3.predict(x_test)\n",
    "print(accuracy_score(model3_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.24617326\n",
      "Iteration 2, loss = 1.13029840\n",
      "Iteration 3, loss = 1.02511688\n",
      "Iteration 4, loss = 0.93112193\n",
      "Iteration 5, loss = 0.84874299\n",
      "Iteration 6, loss = 0.77661861\n",
      "Iteration 7, loss = 0.71334985\n",
      "Iteration 8, loss = 0.65645048\n",
      "Iteration 9, loss = 0.60549756\n",
      "Iteration 10, loss = 0.56084862\n",
      "Iteration 11, loss = 0.52220606\n",
      "Iteration 12, loss = 0.48911707\n",
      "Training loss did not improve more than tol=0.250000 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(alpha=0.25, hidden_layer_sizes=(30,), learning_rate_init=0.01,\n",
      "              max_iter=5000, random_state=1, tol=0.25, verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Training model with different hyperparameters\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(30, ),activation='relu', max_iter=5000, alpha=.25,\n",
    "                    solver='adam', verbose=10, tol=.25, random_state=1,\n",
    "                    learning_rate_init=.01)\n",
    "print(mlp4.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model4_train = mlp4.predict(x_train)\n",
    "print(accuracy_score(model4_train, y_train))\n",
    "model4_test = mlp4.predict(x_test)\n",
    "print(accuracy_score(model4_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.11500664\n",
      "Iteration 2, loss = 0.76841674\n",
      "Iteration 3, loss = 0.58757530\n",
      "Iteration 4, loss = 0.50867225\n",
      "Iteration 5, loss = 0.46481542\n",
      "Iteration 6, loss = 0.43434348\n",
      "Iteration 7, loss = 0.41032906\n",
      "Iteration 8, loss = 0.39012547\n",
      "Iteration 9, loss = 0.37245536\n",
      "Iteration 10, loss = 0.35654747\n",
      "Iteration 11, loss = 0.34186761\n",
      "Iteration 12, loss = 0.32802904\n",
      "Iteration 13, loss = 0.31475508\n",
      "Training loss did not improve more than tol=0.250000 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(activation='tanh', alpha=0.25, hidden_layer_sizes=(20,),\n",
      "              learning_rate_init=0.1, max_iter=5000, random_state=1,\n",
      "              solver='sgd', tol=0.25, verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Training sgd with tanh different hyperparameters\n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(20, ),activation='tanh', max_iter=5000, alpha=.25,\n",
    "                    solver='sgd', verbose=10, tol=.25, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "print(mlp5.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916666666666667\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model5_train = mlp5.predict(x_train)\n",
    "print(accuracy_score(model5_train, y_train))\n",
    "model5_test = mlp5.predict(x_test)\n",
    "print(accuracy_score(model5_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.09914862\n",
      "Iteration 2, loss = 1.08119864\n",
      "Iteration 3, loss = 1.06354163\n",
      "Iteration 4, loss = 1.04618522\n",
      "Iteration 5, loss = 1.02913643\n",
      "Iteration 6, loss = 1.01240173\n",
      "Iteration 7, loss = 0.99598680\n",
      "Iteration 8, loss = 0.97989664\n",
      "Iteration 9, loss = 0.96413575\n",
      "Iteration 10, loss = 0.94870824\n",
      "Iteration 11, loss = 0.93361771\n",
      "Iteration 12, loss = 0.91886713\n",
      "Training loss did not improve more than tol=0.500000 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(activation='tanh', alpha=0.5, hidden_layer_sizes=(30,),\n",
      "              max_iter=5000, random_state=1, tol=0.5, verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Training Adam with Tanh different Hyper Parameters\n",
    "mlp6 = MLPClassifier(hidden_layer_sizes=(30, ),activation='tanh', max_iter=5000, alpha=.5,\n",
    "                    solver='adam', verbose=10, tol=.5, random_state=1,\n",
    "                    learning_rate_init=.001)\n",
    "print(mlp6.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6583333333333333\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model6_train = mlp6.predict(x_train)\n",
    "print(accuracy_score(model6_train, y_train))\n",
    "model6_test = mlp6.predict(x_test)\n",
    "print(accuracy_score(model6_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.73612433\n",
      "Iteration 2, loss = 0.72520004\n",
      "Iteration 3, loss = 0.71453130\n",
      "Iteration 4, loss = 0.70412240\n",
      "Iteration 5, loss = 0.69397585\n",
      "Iteration 6, loss = 0.68409337\n",
      "Iteration 7, loss = 0.67447658\n",
      "Iteration 8, loss = 0.66512648\n",
      "Iteration 9, loss = 0.65604319\n",
      "Iteration 10, loss = 0.64722578\n",
      "Iteration 11, loss = 0.63867235\n",
      "Iteration 12, loss = 0.63038007\n",
      "Training loss did not improve more than tol=0.500000 for 10 consecutive epochs. Stopping.\n",
      "MLPClassifier(activation='identity', alpha=0.25, hidden_layer_sizes=(18,),\n",
      "              max_iter=1000, random_state=1, tol=0.5, verbose=10)\n"
     ]
    }
   ],
   "source": [
    "# Training Adam with Identity different Hyper Parameters\n",
    "mlp7 = MLPClassifier(hidden_layer_sizes=(18, ),activation='identity', max_iter=1000, alpha=.25,\n",
    "                    solver='adam', verbose=10, tol=.5, random_state=1,\n",
    "                    learning_rate_init=.001)\n",
    "print(mlp7.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model7_train = mlp7.predict(x_train)\n",
    "print(accuracy_score(model7_train, y_train))\n",
    "model7_test = mlp7.predict(x_test)\n",
    "print(accuracy_score(model7_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
